# ğŸ§  Little Go Competitive Engine

A compact **5Ã—5 Go AI engine** implemented in **Python + NumPy**, featuring **Alphaâ€“Beta pruning with iterative deepening, aspiration windows, and bitboard compression**.  
This engine was developed for competitive mini-Go environments and achieves over **90% win rate** against standard baselines.

---

## ğŸ“˜ Overview

**Little Go Competitive Engine** is a lightweight yet high-performance AI designed to play 5Ã—5 Go.  
It leverages Alphaâ€“Beta search combined with heuristic move ordering, symmetry reduction, and dynamic evaluation to play competitively within strict time constraints.

---

## âš™ï¸ Technical Highlights

- **Iterative Deepening + Aspiration Window Search** (1â€“5 plies, self-tuned per time limit)
- **Multi-layer Move Ordering:** killer move, history heuristic, transposition table, top-10 filter (â‰ˆ35% node cut)
- **Bitboard Compression:** 5Ã—5 board compressed into 50-bit canonical form (â‰ˆ90% smaller keys)
- **Dynamic Evaluation Function:** territory, liberty, influence, and ko-risk weighting by game phase
- **Transposition Table & Symmetry Canonicalization** to reduce repeated state evaluation
- **Tournament Performance:** ~90% win rate vs greedy, aggressive, and vanilla alpha-beta opponents

---

## ğŸ§© Project Structure

```
Little-Go-Competitive-Engine/
â”‚
â”œâ”€â”€ AlphabetaPlayer.py      # Alpha-Beta pruning player class
â”œâ”€â”€ Board.py                # Board representation and state manipulation
â”œâ”€â”€ chest_alpha.py          # Experimental Alpha-Beta testing script
â”œâ”€â”€ chest.py                # Basic game state control logic
â”œâ”€â”€ input.txt               # Input file containing side and current/previous board states
â”œâ”€â”€ LICENSE                 # License file
â”œâ”€â”€ my_player3.py           # Main AI entry point (iterative deepening + aspiration window)
â”œâ”€â”€ output.txt              # Output file for AI move results
â”œâ”€â”€ qlearnerExp.py          # Q-learning experiment (optional extension)
â”œâ”€â”€ qtable.txt              # Pretrained Q-table values for reinforcement learning variant
â”œâ”€â”€ RandomPlayer.py         # Baseline random move generator for benchmarking
â”œâ”€â”€ README.md               # Project documentation (this file)
â”œâ”€â”€ rule.txt                # Game rule summary for 5Ã—5 Little Go
â””â”€â”€ test.py                 # Unit tests and simulation scripts
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Prepare the Input File (`input.txt`)

```
1
00000
00000
00000
00000
00000
00000
00000
00000
00000
00000
```
- First line: current side (`1` = Black, `2` = White)  
- Next 10 lines: previous and current board states

### 2ï¸âƒ£ Run the Engine

```bash
python3 my_player3.py
```

### 3ï¸âƒ£ Output Example (`output.txt`)
```
2,3
```
This indicates the AI plays at row 2, column 3.

---

## ğŸ§  Core Class â€” AlphabetaPlayer

The core of the AI is implemented in `my_player3.py` as the `AlphabetaPlayer` class.

### Key Methods

| Method | Description |
|--------|--------------|
| `alphabeta()` | Minimax with alphaâ€“beta pruning and killer/history heuristics |
| `choose_move()` | Iterative deepening with aspiration windows and time control |
| `evaluate_board()` | Weighted evaluation combining group structure, territory, liberties, and ko-risk |
| `limit_moves()` | Multi-level move ordering and pruning (top 10 heuristic filtering) |
| `canonical_board()` | Symmetry normalization using 8 rotations/flips |

---

## ğŸ“Š Performance Summary

| Metric | Value |
|--------|-------|
| Board size | 5 Ã— 5 |
| Average search depth | 1â€“5 plies (adaptive) |
| Node reduction | â‰ˆ 35% |
| Transposition table compression | 90% smaller keys |
| Tournament win rate | 90% vs. baselines |
| Average move time | â‰¤ 6 seconds |

---

## ğŸ§© Future Work

- Integrate **Monte Carlo Tree Search (MCTS)** hybrid strategy  
- Add **Zobrist hashing** for faster state lookups  
- Develop a **visual Go board GUI**  
- Incorporate a **neural policy network** for adaptive move ordering  

---

## ğŸ‘¨â€ğŸ’» Author

**Aaron Lin**  
University of Southern California (USC)  
CS561 â€“ Artificial Intelligence / Competitive Game Agent Project  
[GitHub: @w224lin](https://github.com/w224lin)

---
